{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WUDunXR-3YKu",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 6장 의사결정나무"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 감사의 글\n",
    "\n",
    "자료를 공개한 저자 오렐리앙 제롱과 강의자료를 지원한 한빛아카데미에게 진심어린 감사를 전합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hBxgwiZb3iHR",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 의사결정나무 학습과 시각화\n",
    "* (의사결정나무) 예측하기\n",
    "* (의사결정나무) 클래스 확률 추정\n",
    "* (의사결정나무) CART 훈련 알고리즘\n",
    "* (의사결정나무) 계산 복잡도\n",
    "* 지니 불순도 대 엔트로피\n",
    "* (의사결정나무) 규제 매개변수\n",
    "* (의사결정나무) 회귀\n",
    "* (의사결정나무) 불안정성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xjQC0LJV38v0",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 6.1 의사결정나무 학습과 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xjQC0LJV38v0",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 붓꽃 데이터를 이용하여 사이킷런의 의사결정나무 모델을 학습시키고 학습결과 시각화 하기\n",
    "\n",
    "* 붗꼿을 꽃잎의 길이와 너비 기준으로 분류하는 학습\n",
    "\n",
    "* 사이킷런의 `DecisionTreeClassifier` 모델 활용\n",
    "\n",
    "* 의사결정나무 방식의 최대 장점: 데이터 전처리 불필요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xjQC0LJV38v0",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 사이킷런의 의사결정나무 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "hI3XajH935hN",
    "outputId": "6737da16-51d7-473d-9f30-d56480245535",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "```python\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:, 2:] # 꽃잎 길이와 너비\n",
    "y = iris.target\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(max_depth=2, random_state=42)\n",
    "tree_clf.fit(X, y)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xjQC0LJV38v0",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### 사용된 옵션\n",
    "\n",
    "* `max_depth`: 의사결정나무의 최대 깊이 지정.\n",
    "    * 여기서는 2 사용. 즉, 연속된 가지치기가 최대 2번까기 가능."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uQyfP6CW4zPh",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 의사결정나무 학습결과 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uQyfP6CW4zPh",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 사이킷런의 `export_graphviz()` 함수 활용\n",
    "* 훈련 결과를 그래프 정보로 변환한 후 `iris_tree.dot` 파일에 저장\n",
    "* pdf 또는 png 파일로 변환 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/ch06/homl06-01.png\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YgctkyUP5LUL",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 나무 구성 요소\n",
    "\n",
    "* 마디(node): 가지치기가 시작되는 지점\n",
    "* 나무뿌리(root node): 맨 상단에 위치한 마디\n",
    "* 나뭇잎(leaf node): 더 이상의 가기치기가 발생하지 않는 마디"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YkzEuDkB6VoY",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 의사결정나무 마디 속성\n",
    "\n",
    "* `gini`: 해당 마디의 불순도 측정값\n",
    "    * 모든 샘플이 동일 클래스에 속하면 불순도가 0이 됨. 즉, `gini=0`.\n",
    "    * 의사결정나무 학습 과정에 사용되는 알고리즘의 비용함수에 사용됨. \n",
    "        (아래에서 자세히 설명)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YkzEuDkB6VoY",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* `samples`: 해당 마디 결정에 사용된 샘플 수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YkzEuDkB6VoY",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* `value`: 해당 마디 결정에 사용된 샘플을 클래스 별로 구분한 결과\n",
    "  * 훈련 샘플의 레이블 정보를 이용하여 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YkzEuDkB6VoY",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* `class`: 각 클래스별 비율을 계산하여 가장 높은 비율에 해당하는 클래스 선정\n",
    "  * 동일한 비율이면 낮은 인덱스 선정\n",
    "  * 예를 들어, 깊이 2의 왼편 마디의 클래스별 비율은 아래와 같음\n",
    "\n",
    "    $$p_0= 0/54, \\quad p_1=49/54, \\quad p_2 = 5/54$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dYcae39N5kQ2",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 6.2 (의사결정나무) 예측하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "colab_type": "text",
    "id": "dYcae39N5kQ2",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 데이터가 주어지면 나무뿌리에서 시작"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "colab_type": "text",
    "id": "dYcae39N5kQ2",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* 꽃잎 길이: 2.45cm 이하\n",
    "    * 왼편으로 이동. setosa로 판정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "colab_type": "text",
    "id": "dYcae39N5kQ2",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* 꽃잎 길이: 2.45cm 초과\n",
    "    * 오른편으로 이동\n",
    "\n",
    "    * 꽃잎 너비: 1.75cm 이하\n",
    "      * 왼편으로 이동. Iris-Versicolor로 판정\n",
    "\n",
    "    * 꽃잎 너비: 1.75cm 초과\n",
    "      * 오른편으로 이동. Iris-Virginica로 판정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/ch06/homl06-02.png\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* 점선: `max_depth=3`으로 지정할 경우를 보여줌.\n",
    "* `max_depth` 값을 크게 잡으면 과대적합 위험도 커짐."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YkzEuDkB6VoY",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 6.3 (의사결정나무) 클래스 확률 추정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YkzEuDkB6VoY",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 계산된 클래스별 비율을 이용하여 새로운 샘플에 대한 예측 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YkzEuDkB6VoY",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* 예제: 꽃잎 길이와 너비가 각각 5cm, 1.5cm인 붓꽃에 대한 클래스 별 예측확률: \n",
    "    \n",
    "    $$[ 0/54, 49/54, 5/54]$$\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YkzEuDkB6VoY",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* 판정: 가장 높은 확률을 가진 Iris-Versicolor!    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YkzEuDkB6VoY",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* 동일한 마디에 속한 샘플에 대한 예측값은 언제나 동일"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 6.4 (의사결정나무) CART 훈련 알고리즘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H5K56v6g7sJT",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 지니 불순도 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H5K56v6g7sJT",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 불순도: 마디에 포함된 `gini` 속성\n",
    "\n",
    "    * $K$는 클래스 수이고, $p_k$는 클래스 $k$에 속한 샘플의 비율\n",
    "\n",
    "    $$G = 1 - \\sum_{k=0}^{K-1} p_{k}^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H5K56v6g7sJT",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* 예를 들어, 깊이 2의 왼편 마디의 지니 불순도는 0.168\n",
    "\n",
    "    $$G = 1 - (0/54)^2 - (49/54)^2 - (5/54)^2 = 0.168$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "44q4QDKU905A",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 분류와 회귀 나무(CART, classification and regression tree) 알고리즘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "44q4QDKU905A",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 아래 비용함수를 최소화 하는 특성 $k$와 해당 특성의 임곗값 $t_k$을 결정\n",
    "    * 탐욕적 알고리즘(greedy algorithm) 활용\n",
    "\n",
    "    $$\n",
    "    J(k, t_k) = \\frac{m_\\text{left}}{m}\\, G_\\text{left} + \\frac{m_\\text{right}}{m}\\, G_\\text{right}\n",
    "    $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "44q4QDKU905A",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $G_\\text{left}$($G_\\text{right}$):\n",
    "    지정된 특성 $k$와 특성 임곗값 $t_k$로 구분된 왼편(오른편) 부분집합의 지니 불순도\n",
    "    * 즉, 각 마디의 지니 불순도를 낮추는 방향으로 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "44q4QDKU905A",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $m$: 해당 마디의 전체 샘플 수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "44q4QDKU905A",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $m_\\text{left}$($m_\\text{right}$):\n",
    "    지정된 특성 $k$와 특성 임곗값 $t_k$로 구분된 왼편(오른편) 부분집합의 크기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "44q4QDKU905A",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* $J(k, t_k)$가 작을수록 불순도가 낮은 두 개의 부분집합으로 분할됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "44q4QDKU905A",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* 탐욕적 알고리즘은 해당 마디에 포함된 샘플을 지니 불순도가 가장 낮은, 즉, 가장 순수한(pure) 두 개의 부분집합으로 분할"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "44q4QDKU905A",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* 이렇게 나누는 과정은 `max_depth` 깊이에 다다르거나 불순도를 줄이는 분할을 더 이상 찾을 수 없을 때, 또는 다른 규제의 한계에 다다를 때까지 반복"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "65z6hFwC-4ds",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 6.5 (의사결정나무) 계산 복잡도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 최적 의사결정나무 찾기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "65z6hFwC-4ds",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* 최적의 의사결정나무를 찾는 문제는 NP-완전(NP-complete)임."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "65z6hFwC-4ds",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* 이런 문제의 시간 복잡도는 $O(\\exp(m))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "65z6hFwC-4ds",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* 매우 작은 훈련 세트에 대해서도 제대로 적용하기 어려움"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 예측 시간 복잡도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "65z6hFwC-4ds",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 학습된 의사결정나무가 예측에 필요한 시간: $O(\\log m)$\n",
    "    * 훈련 샘플 수 $m$에만 의존하며 매우 빠름\n",
    "    * 특성 수와 무관: 각 마디에서 하나의 특성만 분류기준으로 사용되기 때문"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 학습 시간 복잡도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 훈련 샘플이 크기순으로 정렬된 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "65z6hFwC-4ds",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 각 마디에서 분류하는 데 걸리는 시간: $O(n\\cdot m\\cdot \\log(m))$\n",
    "* 의사결정나무를 완성하는 데 걸리는 시간: $O(n\\cdot m^2\\cdot \\log(m))$ \n",
    "* 규제가 있는 경우 좀 더 빨라짐."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 훈련 샘플을 정렬하는 데 걸리는 시간"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "65z6hFwC-4ds",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* `DecisionTreeClassifier`의 `presort=True` 옵션 설정\n",
    "    * 훈련 세트를 미리 퀵정렬 시킨 후 학습 시작\n",
    "\n",
    "* 훈련 세트가 크면 이 방식은 속도가 늦어짐\n",
    "    * 퀵정렬 자체의 복잡도: $O(m\\log m)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XaVDK_hy___q",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 6.6 지니 불순도 대 엔트로피"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XaVDK_hy___q",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* `DecisionTreeClassifier`의 `criterion=\"entropy\"` 옵션 설정: \n",
    "    * gini 불순도 대신에 엔트로피 불순도 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XaVDK_hy___q",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* 특정 마디의 엔트로피($H$) 계산\n",
    "\n",
    "    $$H = -\\sum_{\\substack{k=0\\\\p_k\\neq 0}}^{K-1} p_{k}\\, \\log(p_k)$$\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XaVDK_hy___q",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* 두 불순도의 차이는 크지 않으며, 비슷한 의사결정나무를 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XaVDK_hy___q",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 엔트로피 불순도 특징:\n",
    "    * 특정 $k$에 대해 만약 $p_k$ 0에 가까운 경우\n",
    "    * $\\log(p_k)$: 음의 무한대로 수렴 \n",
    "    * 엔트로피 증가\n",
    "    * 비용함수 $J(k, t_k)$ 증가\n",
    "    * 그런 조합은 피하게 됨\n",
    "    * 따라서 마디를 보다 균형 잡힙 두 개의 부분집합으로 분할하는 방향으로 유도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XaVDK_hy___q",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* 하지만 지니 불순도가 좀 더 계산이 빠르기에, 기본값으로 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r69il0FtBDTZ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 6.7 (의사결정나무) 규제 매개변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 비매개변수 모델 대 매개변수 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r69il0FtBDTZ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 비매개변수 모델(nonparametric model)\n",
    "\n",
    "* 훈련 시작 전에 파라미터 수가 결정되지 않는 모델\n",
    "* 예제: 의사결정나무. 어떤 모델일지 미리 지정하지 않음.\n",
    "    * 마디를 분할할 수 있는 자유도(degree of freedom) 제함 없음\n",
    "* 과대적합 위험 높음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r69il0FtBDTZ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 매개변수 모델(parametric model)\n",
    "\n",
    "* 미리 정의된 모델 파라미터 사용\n",
    "* 예제: 선형 모델\n",
    "* 과대적합 위험도 줄어듦. \n",
    "* 과소적합 위험도 커딤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r69il0FtBDTZ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 사이킷런  `DecisionTreeClassifier` 규제하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r69il0FtBDTZ",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* `max_depth`: 의사결정나무의 최대 높이 제한"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r69il0FtBDTZ",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* `min_samples_split`: 마디를 분할하기 위해 필요한 최소 샘플 수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r69il0FtBDTZ",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* `min_samples_leaf`:나뭇잎에 포함되어야 하는 최소 샘플 수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r69il0FtBDTZ",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* `min_weight_fraction_leaf`: \n",
    "    * 샘플 별로 가중치가 설정된 경우: 가중치의 전체 합에서 해당 나뭇잎에 포함된 샘플의 가중치의 합이 차지하는 비율\n",
    "    * 샘플 별로 가중치가 없는 경우: `min_samples_leaf`와 동일한 역할 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r69il0FtBDTZ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* `max_leaf_nodes`: 허용된 나뭇잎의 최대 개수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r69il0FtBDTZ",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* `max_features`: 각 마디에서 분할 평가에 사용될 수 있는 최대 특성 수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r69il0FtBDTZ",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* 규제를 높이는 방법\n",
    "    * `min_` 접두사 사용 규제: 값을 키울 것\n",
    "    * `max_` 접두사 사용 규제: 값을 감소시킬 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r69il0FtBDTZ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 예제: 사이킷런  `DecisionTreeClassifier` 규제 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oeGK7R0rCP_I",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### `moons` 데이터셋에 대한 의사결정나무 모델 학습\n",
    "\n",
    "* 왼편: 규제 전혀 없음\n",
    "    * 보다 정교함\n",
    "    * 과대적합됨\n",
    "    \n",
    "* 오른편: `min_samples_leaf=4`\n",
    "    * 일반화 성능 보다 좋음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"images/ch06/homl06-03.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e3NpxtBKChr0",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 사전 가지치기 대 사후 가지치기\n",
    "\n",
    "* 사전 가지치기: 사이킷런의 `DecisionTreeClassifier` 처럼 학습 과정에 사용되는 규제에 따라 분할을 제한하는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e3NpxtBKChr0",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* 사후 가지치기: 우선 제한 없이 의사결정나무를 훈련 시킨 뒤에 통계적 가설검정을 이용하여 별로 의미 없는 마디를 잘라내는 기법\n",
    "    * 사이킷런은 사후 가지치기를 지원하지 않음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "31HcJrG8DBbP",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 6.8 (의사결정나무) 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "31HcJrG8DBbP",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 의사결정나무 알고리즘 아이디어를 거의 그대로 이용하여 회귀 문제에 적용 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ta34qi8vDKE1",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 사이킷런의 `DecisionTreeRegressor` 예측기 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 예제: 잡음이 포함된 2차 함수 형태의 데이터셋\n",
    "\n",
    "* 왼편: `max_depth=2`\n",
    "* 오른편: `max_depth=3`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"images/ch06/homl06-04.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 왼편 그래프에 대한 회귀 그래프"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"images/ch06/homl06-05.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gdPEwMOKD2Ts",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 각 마디에 포함된 속성\n",
    "  * `samples`: 해당 마디에 속한 훈련 샘플 수\n",
    "  * `value`: 해당 마디에 속한 훈련 샘플의 평균 타깃값\n",
    "  * `mse`: 해당 마디에 속한 훈련 샘플의 평균제곱오차(mse)\n",
    "    * 오차 기준은 `value` 사용."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Wv-PadWE4su",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 회귀용 CART 알고리즘의 비용함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "44q4QDKU905A",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 아래 비용함수를 최소화 하는 특성 $k$와 해당 특성의 임곗값 $t_k$을 결정\n",
    "    * 탐욕적 알고리즘(greedy algorithm) 활용\n",
    "    * 각 마디의 평균제곱오차 $MSE$를 최소화하는 방향으로 학습\n",
    "\n",
    "    $$\n",
    "    J(k, t_k) = \\frac{m_\\text{left}}{m}\\, \\text{MSE}_\\text{left} + \\frac{m_\\text{right}}{m}\\, \\text{MSE}_\\text{right}\n",
    "    $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "44q4QDKU905A",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* $\\text{MSE}_\\text{left}$($\\text{MSE}_\\text{right}$):\n",
    "    지정된 특성 $k$와 특성 임곗값 $t_k$로 구분된 왼편(오른편) 부분집합의 평균제곱오차(mse)\n",
    "    <br> \n",
    "    <br>\n",
    "    \n",
    "    * 해당 마디에 속한 샘플들의 평균 타깃값 기준\n",
    "    <br>\n",
    "    \n",
    "    * $m_\\text{node}$: 해당 마디에 속하는 샘플 수\n",
    "    <br>\n",
    "    \n",
    "    * $y^{(i)}$: 샘플 $i$에 대한 레이블"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "44q4QDKU905A",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\\begin{align*}\n",
    "\\text{MSE}_\\text{node} &= \\sum_{i\\in \\text{node}} (\\hat y_{node} - y^{(i)})^2\\\\\n",
    "\\hat y_\\text{node} &= \\frac{1}{m_\\text{node}} \\sum_{i\\in\\text{node}} y^{(i)}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s5CYDKUtFn3b",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 예제\n",
    "\n",
    "* 왼편: 규제가 없는 경우\n",
    "    * 과대적합 발생\n",
    "    \n",
    "* 오른편: `min_samples_leaf=10`\n",
    "    * 나름 괜찮음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"images/ch06/homl06-06.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gppqltl-F3Rc",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 6.9 (의사결정나무) 불안정성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gppqltl-F3Rc",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 의사결정나무 알고리즘은 성능이 매우 우수하지만 기본적으로 주어진 훈련 세트에 민감하게 반응함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gj6GGfQyGDCL",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 단점 1: 훈련 세트의 회전에 민감\n",
    "\n",
    "* 의사결정나무는 항상 축에 수직인 분할을 사용\n",
    "* 따라서 조금만 회전을 가해도 결정 경계가 많이 달라짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gj6GGfQyGDCL",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 예제\n",
    "\n",
    "* 오른편 그래프: 왼편 그래프를 45도 회전시킨 훈련 세트 학습\n",
    "* PCA 기법 등을 사용하여 훈련 샘플 회전시킨 후 학습 가능. (8장 참조)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"images/ch06/homl06-07.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8y7IjEKKGd4j",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 단점 2: 훈련 세트의 작은 변화에 민감"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8y7IjEKKGd4j",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 예제\n",
    "\n",
    "* 붓꽃 데이터에서 하나의 샘플을 제거한 후 학습시킬 때 매우 다르게 학습할 수 있음.\n",
    "* 왼편 그래프: 모든 샘플 대상 훈련\n",
    "* 오른편 그래프: 가장 넓은 Iris-Versicolor 샘플 제거 후 훈련"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<p>\n",
    "<table cellspacing=\"20\">\n",
    "<tr>\n",
    "<td>\n",
    "<img src=\"images/ch06/homl06-08b.png\" width=\"600\"/>\n",
    "</td>\n",
    "<td>\n",
    "<img src=\"images/ch06/homl06-08.png\" width=\"600\"/>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "</p>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [],
   "name": "핸즈온머신러닝_6장.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
